{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d12119f4",
      "metadata": {
        "id": "d12119f4"
      },
      "source": [
        "# Light Sentiment Analysis Demo (RNN, LSTM, GRU, Transformer, BERT)\n",
        "This notebook demonstrates toy sentiment analysis using several model families.\n",
        "Training uses a very small dataset and few epochs for fast demo purposes.\n",
        "Results are illustrative, not production-quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c8f73a71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8f73a71",
        "outputId": "d58c2c96-9c6c-4dfe-a8df-6e35bce4ade8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mInstall complete\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers sentencepiece tensorflow --upgrade\n",
        "print(\"Install complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b092ec",
      "metadata": {
        "id": "d0b092ec"
      },
      "source": [
        "## 1) Tiny Sentiment Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b31f81f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b31f81f5",
        "outputId": "667d1de4-708f-4061-a9f0-f5312e57e211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: It is just another day | Label: neutral\n",
            "Text: This is the worst book I have ever read | Label: negative\n",
            "Text: Amazing performance by the actors | Label: positive\n",
            "Text: I love this movie | Label: positive\n",
            "Text: The food was okay, nothing special | Label: neutral\n",
            "Text: I hate getting up early | Label: negative\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import random\n",
        "\n",
        "data = [\n",
        "    (\"I love this movie\", \"positive\"),\n",
        "    (\"This is the worst book I have ever read\", \"negative\"),\n",
        "    (\"The food was okay, nothing special\", \"neutral\"),\n",
        "    (\"Amazing performance by the actors\", \"positive\"),\n",
        "    (\"I hate getting up early\", \"negative\"),\n",
        "    (\"It is just another day\", \"neutral\")\n",
        "]\n",
        "random.shuffle(data)\n",
        "\n",
        "for s, l in data:\n",
        "    print(f\"Text: {s} | Label: {l}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "743d1584",
      "metadata": {
        "id": "743d1584"
      },
      "source": [
        "## 2) Tokenization & Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "11e74c9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e74c9c",
        "outputId": "2b9c1a4a-f94f-4833-d468-ce29d36419ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 30 Max sequence length: 9\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "texts = [s for s, l in data]\n",
        "labels = [l for s, l in data]\n",
        "\n",
        "label_map = {'negative':0, 'neutral':1, 'positive':2}\n",
        "y = np.array([label_map[l] for l in labels])\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "\n",
        "max_len = max(len(t.split()) for t in texts)\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size, \"Max sequence length:\", max_len)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c50a6b9",
      "metadata": {
        "id": "1c50a6b9"
      },
      "source": [
        "## 3) Build Seq Models (RNN / LSTM / GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "952cd04a",
      "metadata": {
        "id": "952cd04a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, GRU, Dense, GlobalAveragePooling1D\n",
        "\n",
        "def build_seq_model(cell_type='rnn', embedding_dim=32, latent_dim=32):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
        "    if cell_type=='rnn':\n",
        "        model.add(SimpleRNN(latent_dim))\n",
        "    elif cell_type=='lstm':\n",
        "        model.add(LSTM(latent_dim))\n",
        "    elif cell_type=='gru':\n",
        "        model.add(GRU(latent_dim))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5617ae",
      "metadata": {
        "id": "6f5617ae"
      },
      "source": [
        "## 4) Train & Demo Seq Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53069d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53069d74",
        "outputId": "2b07389f-0d96-4644-8e03-b95790450e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "Text: It is just another day | GOLD: neutral | PRED: neutral\n",
            "Text: This is the worst book I have ever read | GOLD: negative | PRED: negative\n",
            "Text: Amazing performance by the actors | GOLD: positive | PRED: positive\n",
            "Text: I love this movie | GOLD: positive | PRED: positive\n",
            "Text: The food was okay, nothing special | GOLD: neutral | PRED: neutral\n",
            "Text: I hate getting up early | GOLD: negative | PRED: negative\n",
            "\n",
            "Training LSTM\n",
            "Predictions:\n",
            "Text: It is just another day | GOLD: neutral | PRED: neutral\n",
            "Text: This is the worst book I have ever read | GOLD: negative | PRED: negative\n",
            "Text: Amazing performance by the actors | GOLD: positive | PRED: positive\n",
            "Text: I love this movie | GOLD: positive | PRED: positive\n",
            "Text: The food was okay, nothing special | GOLD: neutral | PRED: neutral\n",
            "Text: I hate getting up early | GOLD: negative | PRED: negative\n",
            "\n",
            "Training GRU\n",
            "Predictions:\n",
            "Text: It is just another day | GOLD: neutral | PRED: neutral\n",
            "Text: This is the worst book I have ever read | GOLD: negative | PRED: negative\n",
            "Text: Amazing performance by the actors | GOLD: positive | PRED: positive\n",
            "Text: I love this movie | GOLD: positive | PRED: positive\n",
            "Text: The food was okay, nothing special | GOLD: neutral | PRED: neutral\n",
            "Text: I hate getting up early | GOLD: negative | PRED: negative\n"
          ]
        }
      ],
      "source": [
        "\n",
        "models = {}\n",
        "for cell in ['rnn','lstm','gru']:\n",
        "    print('\\nTraining', cell.upper())\n",
        "    m = build_seq_model(cell_type=cell, embedding_dim=32, latent_dim=32)\n",
        "    m.fit(X, y, epochs=50, batch_size=2, verbose=0)\n",
        "    models[cell] = m\n",
        "    print(\"Predictions:\")\n",
        "    preds = np.argmax(m.predict(X, verbose=0), axis=1)\n",
        "    for t, l, p in zip(texts, labels, preds):\n",
        "        pred_label = [k for k,v in label_map.items() if v==p][0]\n",
        "        print(f\"Text: {t} | GOLD: {l} | PRED: {pred_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb99cf9",
      "metadata": {
        "id": "ddb99cf9"
      },
      "source": [
        "## 5) Tiny Transformer (Educational)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "20f06ce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20f06ce2",
        "outputId": "3842ba48-6ba0-4f35-e8f3-5eced2ea1ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions (Tiny Transformer):\n",
            "Text: It is just another day | GOLD: neutral | PRED: neutral\n",
            "Text: This is the worst book I have ever read | GOLD: negative | PRED: negative\n",
            "Text: Amazing performance by the actors | GOLD: positive | PRED: positive\n",
            "Text: I love this movie | GOLD: positive | PRED: positive\n",
            "Text: The food was okay, nothing special | GOLD: neutral | PRED: neutral\n",
            "Text: I hate getting up early | GOLD: negative | PRED: negative\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "\n",
        "def build_tiny_transformer(vocab_size, seq_len, embedding_dim=32, num_heads=2, ff_dim=64):\n",
        "    inp = Input(shape=(seq_len,))\n",
        "    emb = Embedding(vocab_size, embedding_dim)(inp)\n",
        "    attn = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(emb, emb)\n",
        "    x = LayerNormalization(epsilon=1e-6)(attn + emb)\n",
        "    ff = Dense(ff_dim, activation='relu')(x)\n",
        "    ff = Dense(embedding_dim)(ff)\n",
        "    x = LayerNormalization(epsilon=1e-6)(ff + x)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    out = Dense(3, activation='softmax')(x)\n",
        "    model = Model(inp, out)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "trans_model = build_tiny_transformer(vocab_size, max_len)\n",
        "trans_model.fit(X, y, epochs=50, batch_size=2, verbose=0)\n",
        "preds = np.argmax(trans_model.predict(X, verbose=0), axis=1)\n",
        "print(\"Predictions (Tiny Transformer):\")\n",
        "for t, l, p in zip(texts, labels, preds):\n",
        "    pred_label = [k for k,v in label_map.items() if v==p][0]\n",
        "    print(f\"Text: {t} | GOLD: {l} | PRED: {pred_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ef73a6",
      "metadata": {
        "id": "c5ef73a6"
      },
      "source": [
        "## 6) BERT Sentiment (Pretrained, Inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "743055c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743055c8",
        "outputId": "c3b2dbb6-2ed7-44bf-9cb4-8247f0c95933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love this movie | PRED: positive | Score: 1.00\n",
            "Text: This is the worst book I have ever read | PRED: negative | Score: 1.00\n",
            "Text: The food was okay, nothing special | PRED: negative | Score: 0.98\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Use pipeline with model name (no manual TF load needed)\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "texts = [\n",
        "    \"I love this movie\",\n",
        "    \"This is the worst book I have ever read\",\n",
        "    \"The food was okay, nothing special\"\n",
        "]\n",
        "\n",
        "for t in texts:\n",
        "    res = classifier(t)[0]\n",
        "    label = res['label']\n",
        "    if label == 'NEGATIVE':\n",
        "        pred_label = 'negative'\n",
        "    else:\n",
        "        pred_label = 'positive'\n",
        "    print(f\"Text: {t} | PRED: {pred_label} | Score: {res['score']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47223bac",
      "metadata": {
        "id": "47223bac"
      },
      "source": [
        "## Notes\n",
        "- All models are trained on a tiny dataset and few epochs for fast demonstration.\n",
        "- Predictions are illustrative and may not match real-world sentiment.\n",
        "- For real applications, use larger datasets and more epochs, and consider BERT fine-tuning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}