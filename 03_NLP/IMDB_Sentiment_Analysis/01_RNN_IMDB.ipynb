{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13679c84",
   "metadata": {},
   "source": [
    "# RNN for IMDB Sentiment Classification\n",
    "\n",
    "A simple RNN (SimpleRNN) model trained on the IMDB movie reviews dataset. This notebook shows preprocessing, model build, training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0afd8",
   "metadata": {},
   "source": [
    "## 0. Environment / Install (run if needed)\n",
    "Run this cell to install packages if they are missing. On Colab you can skip already installed ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074be153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print('Python', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow if not present\n",
    "# Uncomment and run if needed\n",
    "# !pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ca9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load & preprocess IMDB dataset\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "maxlen = 200\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print('Train shape:', x_train.shape, 'Test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa00f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build SimpleRNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
    "    SimpleRNN(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train (small epochs for demo)\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b08269",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- RNNs are simple but struggle with long-term dependencies. Use LSTM/GRU for better memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
