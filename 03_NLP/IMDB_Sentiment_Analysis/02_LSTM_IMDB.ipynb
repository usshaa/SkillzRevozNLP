{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbdc8fc",
   "metadata": {},
   "source": [
    "# LSTM for IMDB Sentiment Classification\n",
    "\n",
    "An LSTM model trained on IMDB. LSTM uses gates (input, forget, output) to preserve long-term information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce490fb",
   "metadata": {},
   "source": [
    "## 0. Environment / Install (run if needed)\n",
    "Run this cell to install packages if they are missing. On Colab you can skip already installed ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print('Python', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1236d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000\n",
    "maxlen = 200\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae046aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f05f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=3, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0d037",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- LSTM often outperforms vanilla RNNs on longer sequences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
